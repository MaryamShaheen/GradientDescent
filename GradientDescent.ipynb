{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "GradientDescent.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXfo3Z-CUad1",
        "colab_type": "text"
      },
      "source": [
        "# Implementing the Gradient Descent Algorithm\n",
        "\n",
        "In this lab, we'll implement the basic functions of the Gradient Descent algorithm to find the boundary in a small dataset. First, we'll start with some functions that will help us plot and visualize the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q54kwkLxUad2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Some helper functions for plotting and drawing lines\n",
        "\n",
        "def plot_points(X, y):\n",
        "    admitted = X[np.argwhere(y==1)]\n",
        "    rejected = X[np.argwhere(y==0)]\n",
        "    plt.scatter([s[0][0] for s in rejected], [s[0][1] for s in rejected], s = 25, color = 'blue', edgecolor = 'k')\n",
        "    plt.scatter([s[0][0] for s in admitted], [s[0][1] for s in admitted], s = 25, color = 'red', edgecolor = 'k')\n",
        "\n",
        "def display(m, b, color='g--'):\n",
        "    plt.xlim(-0.05,1.05)\n",
        "    plt.ylim(-0.05,1.05)\n",
        "    x = np.arange(-10, 10, 0.1)\n",
        "    plt.plot(x, m*x+b, color)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwYjK0uxUad5",
        "colab_type": "text"
      },
      "source": [
        "## Reading and plotting the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYwTYUohUad6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "3745bbe2-0192-4e2a-c262-52865a09a70d"
      },
      "source": [
        "data = pd.read_csv('data.csv', header=None)\n",
        "X = np.array(data[[0,1]])\n",
        "y = np.array(data[2])\n",
        "plot_points(X,y)\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+v9xM2rbGhag/wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKWdzhr3Uad8",
        "colab_type": "text"
      },
      "source": [
        "## TODO: Implementing the basic functions\n",
        "Here is your turn to shine. Implement the following formulas, as explained in the text.\n",
        "- Sigmoid activation function\n",
        "\n",
        "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$\n",
        "\n",
        "- Output (prediction) formula\n",
        "\n",
        "$$\\hat{y} = \\sigma(w_1 x_1 + w_2 x_2 + b)$$\n",
        "\n",
        "- Error function\n",
        "\n",
        "$$Error(y, \\hat{y}) = - y \\log(\\hat{y}) - (1-y) \\log(1-\\hat{y})$$\n",
        "\n",
        "- The function that updates the weights\n",
        "\n",
        "$$ w_i \\longrightarrow w_i + \\alpha (y - \\hat{y}) x_i$$\n",
        "\n",
        "$$ b \\longrightarrow b + \\alpha (y - \\hat{y})$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si5I4joOUad9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implement the following functions\n",
        "\n",
        "# Activation (sigmoid) function\n",
        "def sigmoid(x):\n",
        "    pass\n",
        "\n",
        "# Output (prediction) formula\n",
        "def output_formula(features, weights, bias):\n",
        "    pass\n",
        "\n",
        "# Error (log-loss) formula\n",
        "def error_formula(y, output):\n",
        "    pass\n",
        "\n",
        "# Gradient descent step\n",
        "def update_weights(x, y, weights, bias, learnrate):\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bImNV7REUad_",
        "colab_type": "text"
      },
      "source": [
        "## Training function\n",
        "This function will help us iterate the gradient descent algorithm through all the data, for a number of epochs. It will also plot the data, and some of the boundary lines obtained as we run the algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbF2ywaHUaeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(44)\n",
        "\n",
        "epochs = 100\n",
        "learnrate = 0.01\n",
        "\n",
        "def train(features, targets, epochs, learnrate, graph_lines=False):\n",
        "    \n",
        "    errors = []\n",
        "    n_records, n_features = features.shape\n",
        "    last_loss = None\n",
        "    weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
        "    bias = 0\n",
        "    for e in range(epochs):\n",
        "        del_w = np.zeros(weights.shape)\n",
        "        for x, y in zip(features, targets):\n",
        "            output = output_formula(x, weights, bias)\n",
        "            error = error_formula(y, output)\n",
        "            weights, bias = update_weights(x, y, weights, bias, learnrate)\n",
        "        \n",
        "        # Printing out the log-loss error on the training set\n",
        "        out = output_formula(features, weights, bias)\n",
        "        loss = np.mean(error_formula(targets, out))\n",
        "        errors.append(loss)\n",
        "        if e % (epochs / 10) == 0:\n",
        "            print(\"\\n========== Epoch\", e,\"==========\")\n",
        "            if last_loss and last_loss < loss:\n",
        "                print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
        "            else:\n",
        "                print(\"Train loss: \", loss)\n",
        "            last_loss = loss\n",
        "            predictions = out > 0.5\n",
        "            accuracy = np.mean(predictions == targets)\n",
        "            print(\"Accuracy: \", accuracy)\n",
        "        if graph_lines and e % (epochs / 100) == 0:\n",
        "            display(-weights[0]/weights[1], -bias/weights[1])\n",
        "            \n",
        "\n",
        "    # Plotting the solution boundary\n",
        "    plt.title(\"Solution boundary\")\n",
        "    display(-weights[0]/weights[1], -bias/weights[1], 'black')\n",
        "\n",
        "    # Plotting the data\n",
        "    plot_points(features, targets)\n",
        "    plt.show()\n",
        "\n",
        "    # Plotting the error\n",
        "    plt.title(\"Error Plot\")\n",
        "    plt.xlabel('Number of epochs')\n",
        "    plt.ylabel('Error')\n",
        "    plt.plot(errors)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dZqQ8zyUaeC",
        "colab_type": "text"
      },
      "source": [
        "## Time to train the algorithm!\n",
        "When we run the function, we'll obtain the following:\n",
        "- 10 updates with the current training loss and accuracy\n",
        "- A plot of the data and some of the boundary lines obtained. The final one is in black. Notice how the lines get closer and closer to the best fit, as we go through more epochs.\n",
        "- A plot of the error function. Notice how it decreases as we go through more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlqgBxOmUaeD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "69dbebe0-486e-4cf2-b853-2373f9d63ef6"
      },
      "source": [
        "train(X, y, epochs, learnrate, True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-90005167daac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearnrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-b30d617fa49c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(features, targets, epochs, learnrate, graph_lines)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_formula\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_formula\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearnrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Printing out the log-loss error on the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHKLVeaKUaeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Activation (sigmoid) function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def output_formula(features, weights, bias):\n",
        "    return sigmoid(np.dot(features, weights) + bias)\n",
        "\n",
        "def error_formula(y, output):\n",
        "    return - y*np.log(output) - (1 - y) * np.log(1-output)\n",
        "\n",
        "def update_weights(x, y, weights, bias, learnrate):\n",
        "    output = output_formula(x, weights, bias)\n",
        "    d_error = y - output\n",
        "    weights += learnrate * d_error * x\n",
        "    bias += learnrate * d_error\n",
        "    return weights, bias"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}